!pip install pandas
!pip install scikit-learn
!pip install keras
!pip install tensorflow
!pip install tensorflow-keras
!pip install sklearn.model_selection
!pip install sklearn.preprocessing
!pip install keras-wrappers-scikit-learn
!pip install scikeras
!pip install sklearn-keras

import keras
import pandas as pd  # Import pandas with alias
from keras.models import Sequential
from keras.layers import Dense
from scikeras.wrappers import KerasRegressor 
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
print(keras.__version__)

#load dataset
dataframe = pd.read_csv("iris.csv", header=None)  # Assuming no header row in your CSV
dataset = dataframe.values
#split into input(x) and output(y) variables
X = dataset[1:,0:4].astype(float)  # Now this should work as intended
Y = dataset[1:,4]

#encode class values as intergers
encoder = LabelEncoder()
encoder.fit(Y)  # Fit on Y, not lowercase y
encoded_Y = encoder.transform(Y)  # Use uppercase Y for consistency

#convert integers to dummy variables(i.e one hot encoded)
dummy_Y = to_categorical(encoded_Y)  # Use uppercase Y

#define baseline model

def baseline_model():
  #create model
  model = Sequential()
  model.add(Dense(8, input_dim=4, activation='relu'))
  model.add(Dense(3, activation='softmax'))
  #Compile model
  model.compile(loss='categorical_crossentropy', 
                optimizer='adam', metrics=['accuracy'])
  return model

estimator = KerasRegressor(build_fn=baseline_model,
                            epochs=200, batch_size=5, verbose=0)
kfold = KFold(n_splits=10, shuffle=True)
results = cross_val_score(estimator, X, dummy_Y, cv=kfold)
print('\n')
print("1_Vaishnavi Boga")
print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))